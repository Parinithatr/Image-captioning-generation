# Image-captioning-generation
Image caption generation using encoder-decoder model
The main aim of this project is to get a little bit of knowledge of deep learning techniques. We use two techniques mainly CNN and LSTM for image classification.
So, to make our image caption generator model, we will be merging these architectures. It is also called a CNN-RNN model(encoder -decoder model).
CNN is used for extracting features from the image. We will use the pre-trained model VGG.
LSTM will use the information from CNN to help generate a description of the image.

Data set used: Flicker dataset




Dataset link:

https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip
https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip

